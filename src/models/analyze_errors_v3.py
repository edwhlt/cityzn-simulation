#!/usr/bin/env python3
"""
Analyse d√©taill√©e des erreurs du mod√®le CityZN - Version 3
- M√©triques multiples pour √©valuer le mod√®le
- Analyse des r√©sidus par cat√©gorie
- Visualisations des erreurs

Usage:
  python analyze_errors_v3.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
import joblib
import json

# Configuration
BASE_DIR = Path(__file__).parent.parent.parent
DATA_PROCESSED_DIR = BASE_DIR / "data" / "processed"
DATA_PREDICTIONS_DIR = BASE_DIR / "data" / "predictions"
MODELS_DIR = BASE_DIR / "models"
VISUALIZATIONS_DIR = BASE_DIR / "visualizations"
VISUALIZATIONS_DIR.mkdir(exist_ok=True, parents=True)

# Style pour les graphiques
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 10)

print("=" * 80)
print("üìä ANALYSE D√âTAILL√âE DES ERREURS - CITYZN v3")
print("=" * 80)

# =====================================================================
# 1. CHARGER DONN√âES ET MOD√àLE
# =====================================================================

print("\nüìÇ √âtape 1: Chargement des donn√©es...")

# Charger dataset
df = pd.read_csv(DATA_PROCESSED_DIR / "final_dataset_v3.csv")
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Filtrer lignes valides (avec bike_count)
df_valid = df[df['bike_count'].notna()].copy()
print(f"   ‚úÖ {len(df_valid):,} lignes valides avec donn√©es r√©elles")

# Charger le mod√®le entra√Æn√©
model_path = MODELS_DIR / "best_model.joblib"
if not model_path.exists():
    print(f"   ‚ùå Mod√®le non trouv√©: {model_path}")
    print(f"   üí° Lancez d'abord: python src/models/train_v3.py")
    exit(1)

model = joblib.load(model_path)
print(f"   ‚úÖ Mod√®le charg√©: {model_path}")

# Charger encoders et features
label_encoders = joblib.load(MODELS_DIR / "label_encoders.joblib")
with open(MODELS_DIR / "feature_columns.json", 'r') as f:
    feature_cols = json.load(f)

print(f"   ‚úÖ {len(feature_cols)} features charg√©es")

# =====================================================================
# 2. PR√âPARER DONN√âES POUR PR√âDICTION
# =====================================================================

print("\nüîß √âtape 2: Pr√©paration des donn√©es...")

# Encoder features cat√©gorielles (d√©j√† fait pendant training normalement)
# On refait au cas o√π
categorical_cols = [
    'highway_type', 'road_category', 'cycleway_type',
    'surface_quality', 'bicycle_access', 'orientation'
]

# Extraire X et y
X = df_valid[feature_cols].copy()
y_true = df_valid['bike_count'].copy()

# Remplir NaN (comme dans l'entra√Ænement)
numeric_cols = X.select_dtypes(include=[np.number]).columns
X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())
X = X.fillna(0)

print(f"   ‚úÖ {len(X):,} √©chantillons pr√™ts pour pr√©diction")

# =====================================================================
# 3. PR√âDICTIONS ET CALCUL M√âTRIQUES
# =====================================================================

print("\nüîÆ √âtape 3: G√©n√©ration des pr√©dictions...")

y_pred = model.predict(X)
y_pred = np.maximum(y_pred, 0)  # Pas de valeurs n√©gatives

# Calculer r√©sidus
residuals = y_true - y_pred
abs_residuals = np.abs(residuals)
pct_residuals = abs_residuals / (y_true + 1) * 100  # +1 pour √©viter division par 0

print(f"   ‚úÖ Pr√©dictions g√©n√©r√©es")

# =====================================================================
# 4. M√âTRIQUES GLOBALES
# =====================================================================

print("\nüìä √âtape 4: Calcul m√©triques globales...")

metrics = {
    'MAE': mean_absolute_error(y_true, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
    'R2': r2_score(y_true, y_pred),
    'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,
    'Median_AE': np.median(abs_residuals),
    'P90_AE': np.percentile(abs_residuals, 90),
    'P95_AE': np.percentile(abs_residuals, 95)
}

print("\n   üéØ M√©triques de performance:")
print(f"      ‚Ä¢ MAE (Mean Absolute Error):     {metrics['MAE']:.2f} v√©los/h")
print(f"      ‚Ä¢ RMSE (Root Mean Squared Error): {metrics['RMSE']:.2f} v√©los/h")
print(f"      ‚Ä¢ R¬≤ (Coefficient de d√©termination): {metrics['R2']:.3f}")
print(f"      ‚Ä¢ MAPE (Mean Absolute % Error):   {metrics['MAPE']:.1f}%")
print(f"      ‚Ä¢ Median AE (Erreur m√©diane):     {metrics['Median_AE']:.2f} v√©los/h")
print(f"      ‚Ä¢ P90 AE (90e percentile):        {metrics['P90_AE']:.2f} v√©los/h")
print(f"      ‚Ä¢ P95 AE (95e percentile):        {metrics['P95_AE']:.2f} v√©los/h")

# =====================================================================
# 5. ANALYSE PAR CAT√âGORIES
# =====================================================================

print("\nüîç √âtape 5: Analyse par cat√©gories...")

# Ajouter pr√©dictions au dataframe
df_valid['y_pred'] = y_pred
df_valid['residual'] = residuals
df_valid['abs_residual'] = abs_residuals
df_valid['pct_residual'] = pct_residuals

# 5.1 Par heure de la journ√©e
print("\n   ‚è∞ Analyse par heure:")
hourly_errors = df_valid.groupby('hour').agg({
    'abs_residual': ['mean', 'median'],
    'bike_count': 'mean'
}).round(2)
print(hourly_errors)

# 5.2 Par jour de la semaine
print("\n   üìÖ Analyse par jour de la semaine:")
days = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
daily_errors = df_valid.groupby('day_of_week').agg({
    'abs_residual': ['mean', 'median'],
    'bike_count': 'mean'
}).round(2)
daily_errors.index = [days[i] for i in daily_errors.index]
print(daily_errors)

# 5.3 Par type de route
print("\n   üõ£Ô∏è  Analyse par type de route:")
# D√©coder highway_type si n√©cessaire
if 'highway_type' in label_encoders:
    df_valid['highway_type_decoded'] = df_valid['highway_type'].apply(
        lambda x: label_encoders['highway_type'].classes_[int(x)] if x >= 0 else 'unknown'
    )
    highway_errors = df_valid.groupby('highway_type_decoded').agg({
        'abs_residual': ['mean', 'median', 'count'],
        'bike_count': 'mean'
    }).round(2)
    highway_errors = highway_errors.sort_values(('bike_count', 'mean'), ascending=False)
    print(highway_errors.head(10))

# 5.4 Par pr√©sence de piste cyclable
print("\n   üö¥ Analyse par infrastructure cyclable:")
if 'has_dedicated_bike_lane' in df_valid.columns:
    bike_lane_errors = df_valid.groupby('has_dedicated_bike_lane').agg({
        'abs_residual': ['mean', 'median'],
        'bike_count': 'mean',
        'edge_id': 'count'
    }).round(2)
    bike_lane_errors.index = ['Sans piste', 'Avec piste']
    print(bike_lane_errors)

# 5.5 Par m√©t√©o
print("\n   üå¶Ô∏è  Analyse par conditions m√©t√©o:")
if 'is_raining' in df_valid.columns:
    weather_errors = df_valid.groupby('is_raining').agg({
        'abs_residual': ['mean', 'median'],
        'bike_count': 'mean',
        'edge_id': 'count'
    }).round(2)
    weather_errors.index = ['Temps sec', 'Pluie']
    print(weather_errors)

# =====================================================================
# 6. VISUALISATIONS
# =====================================================================

print("\nüìà √âtape 6: G√©n√©ration des visualisations...")

# 6.1 Scatter plot: Pr√©dictions vs R√©el
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Plot 1: Scatter avec ligne identit√©
ax1 = axes[0, 0]
ax1.scatter(y_true, y_pred, alpha=0.3, s=20)
max_val = max(y_true.max(), y_pred.max())
ax1.plot([0, max_val], [0, max_val], 'r--', lw=2, label='Pr√©diction parfaite')
ax1.set_xlabel('Valeurs r√©elles (v√©los/h)', fontsize=12)
ax1.set_ylabel('Valeurs pr√©dites (v√©los/h)', fontsize=12)
ax1.set_title(f'Pr√©dictions vs R√©el (R¬≤ = {metrics["R2"]:.3f})', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Distribution des r√©sidus
ax2 = axes[0, 1]
ax2.hist(residuals, bins=50, edgecolor='black', alpha=0.7)
ax2.axvline(x=0, color='r', linestyle='--', lw=2, label='R√©sidu = 0')
ax2.set_xlabel('R√©sidus (r√©el - pr√©dit)', fontsize=12)
ax2.set_ylabel('Fr√©quence', fontsize=12)
ax2.set_title(f'Distribution des r√©sidus (MAE = {metrics["MAE"]:.1f})', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Erreur par heure
ax3 = axes[1, 0]
hourly_mae = df_valid.groupby('hour')['abs_residual'].mean()
ax3.bar(hourly_mae.index, hourly_mae.values, color='steelblue', edgecolor='black')
ax3.set_xlabel('Heure de la journ√©e', fontsize=12)
ax3.set_ylabel('MAE (v√©los/h)', fontsize=12)
ax3.set_title('Erreur moyenne par heure', fontsize=14, fontweight='bold')
ax3.set_xticks(range(24))
ax3.grid(True, alpha=0.3, axis='y')

# Plot 4: Erreur par trafic r√©el (bins)
ax4 = axes[1, 1]
df_valid['traffic_bin'] = pd.cut(df_valid['bike_count'], bins=[0, 10, 50, 100, 200, 1000, 10000], 
                                   labels=['0-10', '10-50', '50-100', '100-200', '200-1000', '1000+'])
bin_errors = df_valid.groupby('traffic_bin', observed=True)['abs_residual'].mean()
ax4.bar(range(len(bin_errors)), bin_errors.values, color='coral', edgecolor='black')
ax4.set_xticks(range(len(bin_errors)))
ax4.set_xticklabels(bin_errors.index, rotation=45)
ax4.set_xlabel('Trafic r√©el (v√©los/h)', fontsize=12)
ax4.set_ylabel('MAE (v√©los/h)', fontsize=12)
ax4.set_title('Erreur moyenne par niveau de trafic', fontsize=14, fontweight='bold')
ax4.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plot_path = VISUALIZATIONS_DIR / "error_analysis_v3.png"
plt.savefig(plot_path, dpi=150, bbox_inches='tight')
print(f"   ‚úÖ Graphiques sauvegard√©s: {plot_path}")
plt.close()

# =====================================================================
# 7. RAPPORT TEXTE
# =====================================================================

print("\nüìù √âtape 7: G√©n√©ration du rapport...")

report_path = VISUALIZATIONS_DIR / "error_analysis_report_v3.txt"
with open(report_path, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("RAPPORT D'ANALYSE DES ERREURS - CITYZN v3\n")
    f.write("=" * 80 + "\n\n")
    
    f.write(f"Date de g√©n√©ration: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"Dataset: final_dataset_v3.csv\n")
    f.write(f"√âchantillons analys√©s: {len(df_valid):,}\n")
    f.write(f"Edges uniques: {df_valid['edge_id'].nunique()}\n\n")
    
    f.write("M√âTRIQUES GLOBALES\n")
    f.write("-" * 80 + "\n")
    for metric, value in metrics.items():
        f.write(f"{metric:20s}: {value:.2f}\n")
    
    f.write("\n\nANALYSE PAR HEURE\n")
    f.write("-" * 80 + "\n")
    f.write(hourly_errors.to_string())
    
    f.write("\n\nANALYSE PAR JOUR\n")
    f.write("-" * 80 + "\n")
    f.write(daily_errors.to_string())
    
    if 'highway_type_decoded' in df_valid.columns:
        f.write("\n\nANALYSE PAR TYPE DE ROUTE (Top 10)\n")
        f.write("-" * 80 + "\n")
        f.write(highway_errors.head(10).to_string())
    
    if 'has_dedicated_bike_lane' in df_valid.columns:
        f.write("\n\nANALYSE PAR INFRASTRUCTURE CYCLABLE\n")
        f.write("-" * 80 + "\n")
        f.write(bike_lane_errors.to_string())
    
    if 'is_raining' in df_valid.columns:
        f.write("\n\nANALYSE PAR M√âT√âO\n")
        f.write("-" * 80 + "\n")
        f.write(weather_errors.to_string())
    
    f.write("\n\n" + "=" * 80 + "\n")
    f.write("INTERPR√âTATIONS ET RECOMMANDATIONS\n")
    f.write("=" * 80 + "\n\n")
    
    # Interpr√©tations automatiques
    f.write("1. QUALIT√â GLOBALE DU MOD√àLE\n")
    if metrics['R2'] > 0.8:
        f.write(f"   ‚úÖ Excellent: R¬≤ = {metrics['R2']:.3f} (>0.8)\n")
    elif metrics['R2'] > 0.6:
        f.write(f"   ‚ö†Ô∏è  Bon: R¬≤ = {metrics['R2']:.3f} (>0.6)\n")
    else:
        f.write(f"   ‚ùå √Ä am√©liorer: R¬≤ = {metrics['R2']:.3f} (<0.6)\n")
    
    f.write(f"\n2. PR√âCISION\n")
    avg_traffic = df_valid['bike_count'].mean()
    relative_mae = (metrics['MAE'] / avg_traffic) * 100
    f.write(f"   ‚Ä¢ Erreur moyenne: {metrics['MAE']:.1f} v√©los/h\n")
    f.write(f"   ‚Ä¢ Trafic moyen: {avg_traffic:.1f} v√©los/h\n")
    f.write(f"   ‚Ä¢ Erreur relative: {relative_mae:.1f}%\n")
    
    f.write(f"\n3. RECOMMANDATIONS\n")
    if metrics['R2'] < 0.7:
        f.write("   ‚Ä¢ Collecter plus de donn√©es (temporelles et spatiales)\n")
        f.write("   ‚Ä¢ Ajouter features: √©v√©nements, vacances, m√©t√©o avanc√©e\n")
    if metrics['MAPE'] > 50:
        f.write("   ‚Ä¢ Mod√®le peu fiable pour faible trafic (MAPE √©lev√©)\n")
        f.write("   ‚Ä¢ Filtrer pr√©dictions < 10 v√©los/h ou utiliser classification\n")

print(f"   ‚úÖ Rapport sauvegard√©: {report_path}")

# =====================================================================
# 8. EXPORT CSV DES ERREURS
# =====================================================================

print("\nüíæ √âtape 8: Export des erreurs d√©taill√©es...")

# Top 100 pires pr√©dictions
worst_predictions = df_valid.nlargest(100, 'abs_residual')[
    ['edge_id', 'timestamp', 'bike_count', 'y_pred', 'residual', 'abs_residual', 
     'hour', 'day_of_week', 'is_weekend', 'is_rush_hour']
].copy()

worst_path = DATA_PREDICTIONS_DIR / "worst_predictions_v3.csv"
worst_predictions.to_csv(worst_path, index=False)
print(f"   ‚úÖ Top 100 pires pr√©dictions: {worst_path}")

# =====================================================================
# 9. R√âSUM√â FINAL
# =====================================================================

print("\n" + "=" * 80)
print("‚úÖ ANALYSE TERMIN√âE!")
print("=" * 80)

print(f"\nüìÅ Fichiers g√©n√©r√©s:")
print(f"   1. {plot_path.relative_to(BASE_DIR)}")
print(f"   2. {report_path.relative_to(BASE_DIR)}")
print(f"   3. {worst_path.relative_to(BASE_DIR)}")

print(f"\nüéØ Performance du mod√®le:")
print(f"   ‚Ä¢ R¬≤ = {metrics['R2']:.3f}")
print(f"   ‚Ä¢ MAE = {metrics['MAE']:.1f} v√©los/h")
print(f"   ‚Ä¢ MAPE = {metrics['MAPE']:.1f}%")
