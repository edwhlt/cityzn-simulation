#!/usr/bin/env python3
"""
Script de prÃ©diction CityZN - Version 3
PrÃ©dit le trafic vÃ©lo pour une date/heure spÃ©cifique sur tous les edges

Usage:
  python predict_v3.py --datetime "2025-11-15 08:00"
  python predict_v3.py --datetime "2025-11-15 17:30" --sample 1000
  python predict_v3.py --datetime "2025-11-15 08:00" --output predictions_rush_hour.csv
"""

import pandas as pd
import numpy as np
import geopandas as gpd
from pathlib import Path
import json
from datetime import datetime
import joblib
import argparse
from tqdm import tqdm

# Paths
BASE_DIR = Path(__file__).parent.parent.parent
DATA_RAW_DIR = BASE_DIR / "data" / "raw"
DATA_PROCESSED_DIR = BASE_DIR / "data" / "processed"
DATA_PREDICTIONS_DIR = BASE_DIR / "data" / "predictions"
MODELS_DIR = BASE_DIR / "models"

print("=" * 80)
print("ğŸš´ CITYZN - PRÃ‰DICTION v3 (Architecture Modulaire)")
print("=" * 80)

# =====================================================================
# ARGUMENTS
# =====================================================================

parser = argparse.ArgumentParser(description="PrÃ©dire le trafic vÃ©lo pour une date/heure spÃ©cifique")
parser.add_argument('--datetime', type=str, required=True, 
                    help='Date et heure de prÃ©diction (format: "YYYY-MM-DD HH:MM")')
parser.add_argument('--sample', type=int, default=None,
                    help='Nombre d\'edges Ã  prÃ©dire (pour test rapide)')
parser.add_argument('--output', type=str, default=None,
                    help='Nom du fichier de sortie (dÃ©faut: predictions_YYYYMMDD_HHMMSS.csv)')
args = parser.parse_args()

# Parser la date
try:
    target_datetime = datetime.strptime(args.datetime, "%Y-%m-%d %H:%M")
except ValueError:
    print(f"âŒ Format de date invalide. Utilisez: YYYY-MM-DD HH:MM")
    print(f"   Exemple: 2025-11-15 08:00")
    exit(1)

print(f"\nğŸ¯ PrÃ©diction pour: {target_datetime.strftime('%A %d %B %Y Ã  %H:%M')}")

# =====================================================================
# 1. CHARGER MODÃˆLE ET MÃ‰TADONNÃ‰ES
# =====================================================================

print("\nğŸ“‚ Ã‰tape 1: Chargement du modÃ¨le...")

model_path = MODELS_DIR / "best_model.joblib"
if not model_path.exists():
    print(f"   âŒ ModÃ¨le non trouvÃ©: {model_path}")
    print(f"   ğŸ’¡ Lancez d'abord: python src/models/train_v3.py")
    exit(1)

model = joblib.load(model_path)
print(f"   âœ… ModÃ¨le chargÃ©: {model_path}")

features_path = MODELS_DIR / "feature_columns.json"
with open(features_path, 'r') as f:
    feature_cols = json.load(f)
print(f"   âœ… {len(feature_cols)} features")

encoders_path = MODELS_DIR / "label_encoders.joblib"
label_encoders = joblib.load(encoders_path)
print(f"   âœ… Label encoders chargÃ©s")

# Afficher mÃ©triques du modÃ¨le
metrics_path = MODELS_DIR / "metrics.json"
if metrics_path.exists():
    with open(metrics_path, 'r') as f:
        metrics = json.load(f)
    print(f"\n   ğŸ“Š Performance du modÃ¨le:")
    print(f"      â€¢ Type: {metrics['model_type']}")
    print(f"      â€¢ RÂ²: {metrics['metrics']['r2']:.3f}")
    print(f"      â€¢ MAE: {metrics['metrics']['mae']:.1f} vÃ©los/h")

# =====================================================================
# 2. CHARGER EDGES STATIQUES
# =====================================================================

print("\nğŸ—ºï¸  Ã‰tape 2: Chargement edges statiques...")

edges_static_path = DATA_PROCESSED_DIR / "edges_static_v3.gpkg"
if not edges_static_path.exists():
    print(f"   âŒ Edges statiques non trouvÃ©s: {edges_static_path}")
    print(f"   ğŸ’¡ Lancez d'abord: python src/preprocessing/create_ml_dataset_v3.py")
    exit(1)

edges = gpd.read_file(edges_static_path)
print(f"   âœ… {len(edges):,} edges chargÃ©s")

# Ã‰chantillon si demandÃ©
if args.sample:
    sample_size = min(args.sample, len(edges))
    edges = edges.sample(n=sample_size, random_state=42)
    print(f"   ğŸ“Š Ã‰chantillon: {len(edges):,} edges")

# =====================================================================
# 3. CHARGER DONNÃ‰ES MÃ‰TÃ‰O
# =====================================================================

print("\nğŸŒ¤ï¸  Ã‰tape 3: Chargement donnÃ©es mÃ©tÃ©o...")

# Chercher fichier mÃ©tÃ©o (timestamped ou unique)
weather_files = list((DATA_RAW_DIR / "weather").glob("weather_data*.json"))
if not weather_files:
    print(f"   âš ï¸  Aucune donnÃ©e mÃ©tÃ©o trouvÃ©e, utilisation de valeurs par dÃ©faut")
    weather_df = pd.DataFrame([{
        'timestamp': target_datetime,
        'temperature_c': 15.0,
        'precipitation_mm': 0.0,
        'wind_speed_kmh': 10.0,
        'is_raining': False
    }])
else:
    # Charger toutes les donnÃ©es mÃ©tÃ©o
    weather_data = []
    for file in weather_files:
        with open(file, 'r') as f:
            data = json.load(f)
            # Structure: {metadata: {...}, weather_data: [...]}
            if isinstance(data, dict) and 'weather_data' in data:
                weather_data.extend(data['weather_data'])
            elif isinstance(data, dict) and 'data' in data:
                weather_data.extend(data['data'])
            elif isinstance(data, list):
                weather_data.extend(data)
            else:
                weather_data.append(data)
    
    weather_df = pd.DataFrame(weather_data)
    if 'timestamp' in weather_df.columns:
        weather_df['timestamp'] = pd.to_datetime(weather_df['timestamp'])
    print(f"   âœ… {len(weather_df)} mesures mÃ©tÃ©o chargÃ©es")

# Trouver la mesure mÃ©tÃ©o la plus proche de target_datetime
weather_df['time_diff'] = abs((weather_df['timestamp'] - target_datetime).dt.total_seconds())
closest_weather = weather_df.loc[weather_df['time_diff'].idxmin()]

print(f"   ğŸ“… MÃ©tÃ©o pour {closest_weather['timestamp']}:")
print(f"      â€¢ TempÃ©rature: {closest_weather['temperature_c']:.1f}Â°C")
print(f"      â€¢ PrÃ©cipitations: {closest_weather['precipitation_mm']:.1f}mm")
print(f"      â€¢ Vent: {closest_weather['wind_speed_kmh']:.1f}km/h")
print(f"      â€¢ Pluie: {'Oui' if closest_weather['is_raining'] else 'Non'}")

# =====================================================================
# 4. CRÃ‰ER FEATURES TEMPORELLES
# =====================================================================

print("\nâ° Ã‰tape 4: GÃ©nÃ©ration features temporelles...")

# Features temporelles
edges['hour'] = target_datetime.hour
edges['day_of_week'] = target_datetime.weekday()
edges['is_weekend'] = int(target_datetime.weekday() >= 5)
edges['is_rush_hour_morning'] = int(target_datetime.hour in [7, 8, 9])
edges['is_rush_hour_evening'] = int(target_datetime.hour in [17, 18, 19])

print(f"   âœ… Features temporelles:")
print(f"      â€¢ Heure: {target_datetime.hour}h")
print(f"      â€¢ Jour: {['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'][target_datetime.weekday()]}")
print(f"      â€¢ Weekend: {'Oui' if edges['is_weekend'].iloc[0] else 'Non'}")
print(f"      â€¢ Rush hour matin: {'Oui' if edges['is_rush_hour_morning'].iloc[0] else 'Non'}")
print(f"      â€¢ Rush hour soir: {'Oui' if edges['is_rush_hour_evening'].iloc[0] else 'Non'}")

# =====================================================================
# 5. AJOUTER FEATURES MÃ‰TÃ‰O
# =====================================================================

print("\nğŸŒ¦ï¸  Ã‰tape 5: Ajout features mÃ©tÃ©o...")

edges['temperature_c'] = closest_weather['temperature_c']
edges['precipitation_mm'] = closest_weather['precipitation_mm']
edges['wind_speed_kmh'] = closest_weather['wind_speed_kmh']
edges['is_raining'] = int(closest_weather['is_raining'])

# Features mÃ©tÃ©o dÃ©rivÃ©es (comme dans training)
edges['is_cold'] = int(closest_weather['temperature_c'] < 5)
edges['is_hot'] = int(closest_weather['temperature_c'] > 30)
edges['is_windy'] = int(closest_weather['wind_speed_kmh'] > 30)

print(f"   âœ… Features mÃ©tÃ©o ajoutÃ©es")

# =====================================================================
# 6. ENCODER FEATURES CATÃ‰GORIELLES
# =====================================================================

print("\nğŸ”§ Ã‰tape 6: Encodage features catÃ©gorielles...")

categorical_cols = [
    'highway_type', 'road_category', 'cycleway_type',
    'surface_quality', 'bicycle_access', 'orientation'
]

for col in categorical_cols:
    if col in edges.columns and col in label_encoders:
        # GÃ©rer valeurs inconnues
        edges[col] = edges[col].fillna('unknown')
        
        # Encoder (gÃ©rer les valeurs non vues pendant training)
        le = label_encoders[col]
        edges[col] = edges[col].apply(
            lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else -1
        )

print(f"   âœ… {len(categorical_cols)} colonnes encodÃ©es")

# =====================================================================
# 7. PRÃ‰PARER FEATURES POUR PRÃ‰DICTION
# =====================================================================

print("\nğŸ“‹ Ã‰tape 7: PrÃ©paration features finales...")

# VÃ©rifier que toutes les features requises sont prÃ©sentes
missing_features = set(feature_cols) - set(edges.columns)
if missing_features:
    print(f"   âš ï¸  Features manquantes: {missing_features}")
    # Ajouter avec valeurs par dÃ©faut
    for feat in missing_features:
        if 'lag' in feat or 'rolling' in feat:
            edges[feat] = 0  # Pas de donnÃ©es historiques pour prÃ©diction future
        else:
            edges[feat] = 0

# Extraire X dans le bon ordre
X = edges[feature_cols].copy()

# Remplir NaN
numeric_cols = X.select_dtypes(include=[np.number]).columns
X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())
X = X.fillna(0)

print(f"   âœ… {len(X):,} lignes Ã— {len(feature_cols)} features prÃªtes")

# =====================================================================
# 8. PRÃ‰DICTION
# =====================================================================

print("\nğŸ”® Ã‰tape 8: PrÃ©diction en cours...")

predictions = model.predict(X)
edges['bike_count_predicted'] = predictions

# Arrondir et s'assurer que c'est positif
edges['bike_count_predicted'] = edges['bike_count_predicted'].clip(lower=0).round(0).astype(int)

print(f"   âœ… PrÃ©dictions effectuÃ©es")
print(f"\n   ğŸ“Š Statistiques des prÃ©dictions:")
print(f"      â€¢ Moyenne: {edges['bike_count_predicted'].mean():.1f} vÃ©los/h")
print(f"      â€¢ MÃ©diane: {edges['bike_count_predicted'].median():.0f} vÃ©los/h")
print(f"      â€¢ Min: {edges['bike_count_predicted'].min():.0f} vÃ©los/h")
print(f"      â€¢ Max: {edges['bike_count_predicted'].max():.0f} vÃ©los/h")

# =====================================================================
# 9. SAUVEGARDE RÃ‰SULTATS
# =====================================================================

print("\nğŸ’¾ Ã‰tape 9: Sauvegarde des rÃ©sultats...")

# Timestamp pour fichier
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Nom fichier de sortie
if args.output:
    output_filename = args.output
else:
    output_filename = f"predictions_{timestamp}.csv"

# CSV avec colonnes essentielles
output_cols = [
    'osm_id', 'bike_count_predicted', 'highway_type', 'road_category',
    'edge_length_m', 'has_dedicated_bike_lane', 'bike_lane_distance_m',
    'distance_to_center_km', 'hour', 'day_of_week', 'is_weekend', 'is_rush_hour_morning', 'is_rush_hour_evening',
    'temperature_c', 'precipitation_mm', 'is_raining'
]

# Filtrer colonnes existantes
output_cols_existing = [col for col in output_cols if col in edges.columns]

predictions_csv = DATA_PREDICTIONS_DIR / output_filename
edges[output_cols_existing].to_csv(predictions_csv, index=False)
print(f"   âœ… CSV sauvegardÃ©: {predictions_csv}")

# GeoJSON pour visualisation
output_geojson = output_filename.replace('.csv', '.geojson')
predictions_geojson = DATA_PREDICTIONS_DIR / output_geojson

# PrÃ©parer GeoDataFrame pour export
edges_export = edges[output_cols_existing + ['geometry']].copy()
edges_export.to_file(predictions_geojson, driver='GeoJSON')
print(f"   âœ… GeoJSON sauvegardÃ©: {predictions_geojson}")

# MÃ©tadonnÃ©es
metadata = {
    'prediction_datetime': target_datetime.isoformat(),
    'generated_at': datetime.now().isoformat(),
    'model_path': str(model_path.relative_to(BASE_DIR)),
    'n_edges': len(edges),
    'weather': {
        'temperature_c': float(closest_weather['temperature_c']),
        'precipitation_mm': float(closest_weather['precipitation_mm']),
        'wind_speed_kmh': float(closest_weather['wind_speed_kmh']),
        'is_raining': bool(closest_weather['is_raining'])
    },
    'temporal': {
        'hour': int(target_datetime.hour),
        'day_of_week': int(target_datetime.weekday()),
        'is_weekend': bool(target_datetime.weekday() >= 5),
        'is_rush_hour_morning': bool(target_datetime.hour in [7, 8, 9]),
        'is_rush_hour_evening': bool(target_datetime.hour in [17, 18, 19])
    },
    'statistics': {
        'mean': float(edges['bike_count_predicted'].mean()),
        'median': float(edges['bike_count_predicted'].median()),
        'min': int(edges['bike_count_predicted'].min()),
        'max': int(edges['bike_count_predicted'].max()),
        'total': int(edges['bike_count_predicted'].sum())
    }
}

metadata_filename = output_filename.replace('.csv', '_metadata.json')
metadata_path = DATA_PREDICTIONS_DIR / metadata_filename
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"   âœ… MÃ©tadonnÃ©es sauvegardÃ©es: {metadata_path}")

# =====================================================================
# 10. RÃ‰SUMÃ‰ FINAL
# =====================================================================

print("\n" + "=" * 80)
print("âœ… PRÃ‰DICTION TERMINÃ‰E!")
print("=" * 80)

print(f"\nğŸ¯ RÃ©sumÃ©:")
print(f"   â€¢ Date/heure: {target_datetime.strftime('%d/%m/%Y Ã  %H:%M')}")
print(f"   â€¢ Edges prÃ©dits: {len(edges):,}")
print(f"   â€¢ Trafic total prÃ©dit: {edges['bike_count_predicted'].sum():,} vÃ©los/h")
print(f"   â€¢ Trafic moyen: {edges['bike_count_predicted'].mean():.1f} vÃ©los/h/edge")

print(f"\nğŸ“ Fichiers gÃ©nÃ©rÃ©s:")
print(f"   1. {predictions_csv.relative_to(BASE_DIR)}")
print(f"   2. {predictions_geojson.relative_to(BASE_DIR)}")
print(f"   3. {metadata_path.relative_to(BASE_DIR)}")

print(f"\nğŸ”¥ Top 10 edges avec le plus de trafic:")
top_edges = edges.nlargest(10, 'bike_count_predicted')[['osm_id', 'bike_count_predicted', 'highway_type', 'has_dedicated_bike_lane']]
for idx, row in top_edges.iterrows():
    bike_lane = "ğŸš´" if row['has_dedicated_bike_lane'] else "  "
    print(f"   {bike_lane} Edge {row['osm_id']}: {row['bike_count_predicted']:4d} vÃ©los/h ({row['highway_type']})")

print(f"\nğŸ’¡ Visualisation:")
print(f"   Ouvrir {predictions_geojson.name} dans QGIS ou kepler.gl")
